\documentclass{article}
\usepackage{style}
\usepackage{amsmath}
\begin{document}
\maketitle
\part{Introducción}
\section{Neural Networks}

\subsection{Usos principales de las redes neuronales}

Se tienen 4 usos principales de las redes neuronales artificiales (RNA)
\begin{enumerate}
	\item Aproximación de sistemas (Modo regresor)
	\item Predicción de series de tiempo (Modo regresor)
	\item Control de Sistemas (Modo regresor)
	\item Clasificación de objetos (Modo Clasificador)
\end{enumerate}
\subsection{Aproximación de Sistemas}
Dado un sistema $f(t_i)$ del cuál se desconoce su modelo matemático, pero se cuenta con un conjunto de datos entrada-salida $(p, t)$ que representa su comportamiento. Se puede entrenar una RNA para que se comporte de manera similar a $f(t_i)$ en donde:\\\\
$t_i$ : Es la variable de tiempo\\
$p$ : Es la entrada (input)\\
$t$ : El valor deseado (target)\\

\subsection{Modelo Matemático}
Es una representación abstracta que aproxima al comportamiento de un fenómeno real, normalmente mediante un conjunto de ecuaciones.

\subsection{Ecuación}
Igualdad

\subsection{Datos input-output}
Es un conjunto de valores que muestrea mediante sensores el comportamiento dinámico del sistema en todo su rango de funcionamiento

\subsection{Buena Interpolación}
Se llama generación de conocimiento

\subsection{Mala Interpolación}
Se le llama sobrentendimiento

\textbf{LA RED EN MODO REGRESIÓN FUNCIONA COMO UN INTERPOLADOR}

\subsection{Extrapolar}
Pronosticar o predecir, se requieren RNA's recurrentes.

\subsection{Diagrama General}
\begin{figure}[h]
	\caption{Diagrama General}
	\includegraphics[scale=0.6]{modeloGeneralRn}
\end{figure}

\section{Tipos de Aprendizaje}
\subsection{Aprendizaje Supervisado}
Es aquel en el que se cuenta con ejemplos que contienen valores deseados(target) para llevar a cabo el ajuste de los parámetros de la RNA. En este caso se cuenta con un conjunto de datos$(p, t)$;

\subsection{Aprendizaje no Supervisado}
No se cuenta con ejemplos que contengan valores deseados. Sin embargo, existen diversos algoritmos en esta clasificación que se usan para analizar y extraer información valiosa de una fenómeno, por ejemplo, el algoritmo $k-medias$ recibe como entrada un conjunto de datos y un valor $k$ que representa el número de clases en los que se desea separar a dicho conjunto. Dependiendo del valor de $k$ el usuario podrá analizar de diferentes maneras el fenómeno.

\section{Predicción de Series de tiempo}
Dada una serie de tiempo que representa un fenómeno físico, existe un tiempo especial de RNA que es capaz de pronosticar valores futuros, es decir, realiza la correcta extrapolación de datos. Para esta tarea se hace uso de las RNA's recurrrentes.
\begin{figure}
	\centering
	\caption{Ejemplo de extrapolación}
	\includegraphics[scale=.4]{exampleTime}	
\end{figure}

\begin{figure}
	\centering
	\caption{Red Feed Foward}
	\includegraphics[scale=.5]{feedFowardExample}	
\end{figure}

\begin{figure}
	\centering
	\caption{Red Recurrente}
	\includegraphics[scale=.8]{recurrentExample}	
\end{figure}

\begin{figure}
	\centering
	\caption{Red Recurrente con bloques recurrentes}
	\includegraphics[scale=.37]{recurrentExample2}	
\end{figure}

\section{Control de Sistemas}
Dado un sistema $f(t)$ se requiere modificar su comportamiento para que sea estable. En esta aplicación se usa una RNA para aproximar a $f(t)$ y una RNA para diseñar un controlador.

\begin{figure}
	\centering
	\caption{System Control Example}
	\includegraphics[scale=.37]{systemControlExample1}	
\end{figure}

\part{Aplicaciones de la RNA}
\section{Reporte de Práctica}
\begin{enumerate}
	\item Intro
	\item Metodología
	\item Pseudo código
	\item Resultados(Discusión)
	\item Conclusiones
	\item Referencias(mínimo 2)
\end{enumerate}
\section{Clasificación de Objetos}
Consiste en tener una adecuada separación de un conjunto de objetos mediante una función de semejanza.
\begin{enumerate}
	\item Clasificación supervisada:\\
	Aquí se cuenta con un conjunto de objetos y se conoce a que clase pertenence cada uno de ellos.\\
	Una RNA en modo clasificador puede usar una o más salidas para represtnar a que calse considera que un dato de entrada pertenece.\\
	Aquí tenemos targets ya que tenemos un conjunto de clases a las que este se puede etiquetar.\\
	Las redes pueden ser entrenadad no supervisadamente y supervisadamente\\
	Ejemplos:
	\begin{itemize}
		\item \begin{figure}[h!]
			\includegraphics[scale=.2]{appEx1}
		\end{figure}
		\item \begin{figure}[h!]
			\includegraphics[scale=.2]{appEx2}
		\end{figure}
	\end{itemize}

\end{enumerate}
\section{Neurona Biológica}
Los sistemas biolgcos son tan complejos que se han convertido en una excelente fuente de inspiración para diseñar sistemas artificiales, que emulen algunas de sus características, entre ellas se encuentras las siguientes
\begin{enumerate}
	\item No siempre requieren de módulos de referencia (targets)
	\item Se desempeñan exitosamente ante incertidumbres
	\item Se adaptan fácilmente a nuevos ambientes
	\item Pueden Procesar información de diversas fuentes en forma simultánea
\end{enumerate}
Dado que las RNA nacieron de los elementos básicos de una neurona biológica, es bioinspirada.\\
Los componentes básicos de una neurona biológica son:\\
\begin{figure}[h!]
	\includegraphics[scale=.20]{bioNeuron}
\end{figure}\\
donde:\\
$P_1,\ldots,P_r$: Son Entradas\\
$W_1, \ldots, W_r$: Son los pesos sinápticos\\
Los pesos sinápticos se usan para indicar el nivel de importancia de cada una de las conexiones para una tarea particular.\\
El soma se encarga de acumular energía y determinar cuando se generará una señal de salida.\\
\textbf{Nota: Para un target o tarea deseada, aprendizaje es buescar un conjutno de $W_1$ a $W_r$ tales que la salida de la red desea igual al target, para todos los datos del conjutno de entramiento}
\part{Arquitecturas de Redes}
\section{Notación}
\begin{itemize}
	\item Valores escalaras: minúsculas
	\item Valores vectoriales: Mayúsculas
\end{itemize}
\section{Modelo de neurona con una entrada}
\begin{figure}[h!]
	\includegraphics[scale=.3]{mculloc1}
\end{figure}
El bias es una entrada artificial que por definición tendrá siempre un peso sináptico de 1.\\
El bias como parámetro extra, le permite a la red resolver problemas más complejos, aunque existen RNA sin bias.\\
\newpage
Ejemplo:\\
Siendo p=2, w=3 y b=-1.5, sustituya en el modelo de la neurona con 1 entrada.\\
$a = f(4.5)$
\section{Neurona con múltiples entradas}
Típicamente, para resolver un problema, una neurona tiene más de una entrada. Estas se representan como $p_1, p_2, p_3, \ldots p_r$ y a cada una le corresponde un peso sináptico $w_{11}, w_{12}, \ldots, w_{1r}$\\
\begin{figure}[h!]
	\includegraphics[scale=.3]{nneuron}
\end{figure}\\
En forma matricial, se puede expresar:\\
$n = W*P + b$\\
Donde n es un escalar\\
W es una matriz de [1Xr]\\
P es una matriz de [rx1]\\
b es una escalar\\
R es el número de entradas\\
1 es el número de neuronas\\

Finalmente, la salida de la red es:\\
$a = f(WP + b)$\\
Nota:\\
Para este caso particular, la matriz de pesos W es un vecotr fila, ya que representa el número de neuronas en cada capa de la RNA
\subsection{Índices de la matriz W}
Durante el curso, se utilizó la siguiente convención para los índices de la matriz de pesos:\\
\begin{enumerate}
	\item El primer índice, se refiere a la Neurona a la que llega a la conexión.
	\item El segundo índice indica el número  de la \textbf{Fuente} de la que proviene el dato
\end{enumerate}
\subsection{Representación Gráfica matricial}
\begin{figure}[h!]
	\includegraphics[scale=.3]{matrixgrep}
\end{figure}
\newpage
\section{Múltiples neuronas en Paralelo con múltiples entradas(Una capa)}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=.3]{layersmodel}
	\caption{Arquitectura  ``Capa de neuronas''}
\end{figure}
$a = f(w*p+b)$\\
donde las dimensiones de w son: SxR\\
las dimensiones de P son: RxS\\
las dimensiones de b son Sx1
\newpage
\subsection{Diagrama Simplificado}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=.3]{simpdiagram}
	\caption{Arquitectura  ``Capa de neuronas'' en diagrama simplificado}
\end{figure}
\subsection{Ejemplo con s = 1}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=.3]{matrixejpar}
	\caption{Matriz de pesos $W_i$}
\end{figure}
\subsubsection{Nota acerca de las capas}
Algunos autores llaman al vector de entrada P ``Capa de entrada''.\\
Sin embargo, como en ella no se llevan a cabo operaciones, durante el curso \textbf{NO LO HAREMOS}
\begin{itemize}
	\item Capas Ocultas: Se les llama así porque no tiene contacto con el exterior(Hidden Layers)
	\item Capa de Salida: Es aquella que entrega el resultado
\end{itemize}

\section{Multiples Capas de Neuronas}
Ahora se considerará una RNA con varias entradas y múltiples capas. Cada capa tiene su propia matriz de pesos $w$, vector de bias $b$ y vector de salida $a$. Para distinguir entre cada capa, agregamos un superíndice o la variable.
$$ a^1 = f^1(w_s^1p_r^1b_s^1)$$ $$a^2=f^2(w^2a^1+b_s^2)$$
\begin{figure}[h!]
	\centering
	\includegraphics[scale=1]{rainbowmodel}
	\caption{Modelo Arcoiris}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=.4]{rainbowsingle}
	\caption{Capa del modelo arcoiris}
\end{figure}
\newpage
\section{Arquitectura totalmente conectada (O densa)}
$$ a^2 = f^2[w^2f^1(w^1p+b^1)+b^2] $$
Para representar una arquitectura multicapa, (MLP-Multilayer-Perceptron) se utiliza notación:$$ [R\ S^1\ S^2 \ S^3 \dots\ S^m]$$
Donde:\\
R: Es el número de entradas\\
M: Es el número de capas.\\
$S^1 \dots\ S^m$: El número de neuronas en cada capa
\subsection{Ejemplo}
[4 2 5 1]\newline
[$P$] = 4x1\newline
[$w^1$] = 2x4\newline
[$w^2$] = 5x2\newline
[$w^3$] = 1x5\newline
[$b^1$] = 2x1\newline
[$b^2$] = 5x1\newline
[$b^3$] = 1x1
\section{Multilayer Perceptron (MLP)}
La arquitectura mínima de un MLP es [$R$ $S^1$ $S^2$], pero ¿Cómo seleccionas la arquitectura?\\
Debemos partir de las especificaciones del problema, ello nos permite definir lo siguiente:
\begin{enumerate}
	\item El número de entradas (R) al MLP es igual al número de rasgos o variables usados en el problema
	\item El número de neuronas en la capa de salida es igual al número de clases definida en el problema
	\item El tipo de función de activación depende de las consideraciones del problema
	\item En cuanto al número de capas ocultas y al número de neuronas en cada una de ellas, sigue siendo un problema abierto
\end{enumerate}
\subsection{Ejemplo}
Determinemos la arquitectura que clasifique los siguientes objetos en 2 clases\\
\diagram{$O_1=$}{$R_1$\\$R_2$\\$R_3$} \diagram{$O_2=$}{$R_1$\\$R_2$\\$R_3$} \diagram{$O_3=$}{$R_1$\\$R_2$\\$R_3$} \diagram{$O_4=$}{$R_1$\\$R_2$\\$R_3$}\newline
[3 \hspace{10px} 2]
\subsection{Uso del MLP}
\begin{itemize}
	\item Para problemas de aproximación de señales, es común pensar que la dimensión de la señal de entrada Sea R=1. Se usan 1 o 2 capas ocultas y una neurona de la capa de salida
\end{itemize}
\section{Funciones de transferencia}
\subsection{Función Hardlim}
Esta función genera un cero como salida si n es menor a cero y uno si el valor de n es mayor o igual a cero($n \ge 0$).\\
Esta función se usa para crear neuronas capaces de clasificarlas entradas en dos clases.
\begin{figure}[h!]
	\centering
	\includegraphics[scale=.2]{hardlim}
	\caption{Función HardLim}
\end{figure}
\newpage
\subsection{Función Lineal}
En esta función la salida es igual a la entrada
$$a = n$$\\
Este tipo de función se usa para trareas de regresión(aproximación de señales), por ejemplo la red ADALINE
\begin{figure}[h!]
	\centering
	\includegraphics[scale=.2]{purelim}
	\caption{Función PureLim}
\end{figure}
\subsubsection{Ejemplo}
Aproximación de señales\\
\begin{figure}[h!]
	\centering
	\includegraphics[scale=.2]{purelimexample}
	\caption{Ejemplo de aproximación de señales}
\end{figure}
Conjuntos: entrenamiento, aprendizaje, validación y prueba\\
Si logra interpolar bien, se dice que logró la generalización del conocimiento ya que error=t-a$\rightarrow$ 0
\subsection{Función logsigmoid}
Esta función toma como entrada n que puede tener valores entre $-\inf$ y $+\inf$; y la reduce a una salida en el rando de 0 a 1, de acuerdo a la siguiente expresión
$$a = \frac{1}{1 + e^{-n}}$$
\begin{figure}[h!]
	\centering
	\includegraphics[scale=.2]{logsig}
	\caption{Función logsig}
\end{figure}
Esta función es usada comúnmente en redes neuronales multicapa que son entrenadas mediante el algoritmo backpropagation debdo a que esta técnica requiere que las funciones de transferencia de las capas ocultas sean no lineales, continuas y diferenciables.\\
\textbf{La linea que separa las clases se llama frontera de desición}

\section{Red Hamming}
Esta RNA fue diseñada explicitamente para resolver problemas de reconocimiento de patrones binarios (+1 o -1). Esta RNA es interesante, debido a que usa dos tipos de capas, una feed foward y otra recurrente. En hamming el mismo número de neuronas \textbf{AQUI VA UNA FOTO}\\

\subsection{Observaciones}
\begin{enumerate}
	\item El número de neuronas en ambas capas, es el mismo, s
	\item La capa recurrente no tiene bias
	\item La recurrencia se lleva a cabo usando la señal de salida $a^2(t)$ como entrada a los pesos $W^2$
\end{enumerate}

\subsection{Capa FeedForward}
Esta capa calcula la correlación o producto interno entre cada unos de los vecgores protitipo y e patrón de entrada. Con este objetivo, as filas de la matriz de pesos $W_1$, serán cada uno de los patrones prototipo.\\
Para el ejemplo de clasificar una fruta en manzanas y naranjas, la matriz queda como:

\[
W^1 = 
\begin{bmatrix}
	p_1^t\\
	p_2^t
\end{bmatrix}
=
\begin{bmatrix}
+1 & -1 &- 1 \\
+1 & +1 & -1
\end{bmatrix}
\]
\textbf{Nota: Naraja es el primer renglón y manzana el segundo}\\
El valor del bias,$b^1$ es igual a R. Para nuestro ejemplo:\\
donde $S = 2$, ya que es igual al número de patrones prototipo. \textbf{Nota: Al agregar el valor R, se garantiza que las salidas de esta capa no sean negativas, lo cual es necesario para el correcto funcionamiento de la capa recurrente}

\subsection{Capa Recurrente}
Las neuronas de esta capa se inicializan con las salidas de la capa feed foward. En esta capa las neuronas compiten entre ellas para determinar a la ganadora.\\ Al final de la competencia, solo una neuronas de esta capa tendrás un valor diferente de cero.\\\\
La neurona ganadora indica a que clase pertence el vector de entrada. Las ecuaciones que describen esta capa son:
$$ a^2(0) = a^1$$
$$ a^2(t + 1) = poslin(W^2a^2(t)) $$
La matriz de pesos tiene la siguiente forma para el ejemplo:
\[
W^2 = 
\begin{bmatrix}
1 & - \epsilon\\
-\epsilon & 1
\end{bmatrix}
\]

donde:\\
$\epsilon$ es un valor menor a $\frac{1}{S - 1}$\\
S: es el número de neuronas en la capa recurrente\\

Para nuestro ejemplo, una iteración de la capa recurrente, se lleva a cabo con la siguiente ecuación:\\

\[
a^2(t + 1) = poslin
(\begin{bmatrix}
1 & - \epsilon\\
-\epsilon & 1
\end{bmatrix}
\begin{bmatrix}
a_1^2(t)\\
a_2^2(t)
\end{bmatrix})
\]

Esta capa seguirá realizando iteraciones hasta que converja a una solución donde una sola de las neuronas tenga un valor diferente de cero y se reputa en dos iteraciones consecutivas.\\

\subsection{Solución al problema de clasificación}
Indique a que clase pertenece el siguiente vector de entrada usando la red de hamming\\

\[
p =
\begin{bmatrix}
-1 \\
-1\\
-1
\end{bmatrix}
\]
Comenzamos calculando la capa feed foward esto se hace sollo una vez:\\
$$ a^1 = W^1p + b^1 $$\\

\[
a^1 =
\begin{bmatrix}
+1 &  - 1& -1\\
+1 &  + 1& -1
\end{bmatrix}
\begin{bmatrix}
-1 \\
-1 \\
-1
\end{bmatrix}
+
\begin{bmatrix}
3 \\
3 
\end{bmatrix}
=
\begin{bmatrix}
4 \\
2 
\end{bmatrix}
\]

Ahora se pasa a la capa de recurrente

$$ 0 < \epsilon < \frac{1}{S - 1} = 1 $$\\
Se propone $\epsilon$ = 0.5\\
Se realza la primera iteración
t = 0 $\rightarrow a^2(0) = a^1 = $  

\section{Red de Holfield}
Esta RNA es recurrente y con una sola capa es capaz de realizar las operaciones de la red de Hamming.\\
La red de Hamming no siempre va a converger.Esto sucede si dos o más vectores prototipo son equidistantes.
\begin{figure}[h!]
	\caption{Arquitectura de la red de hopfiled}
	\centering
	\includegraphics[scale=.3]{hopfieldArchitecture}
\end{figure}
\[satlints = \begin{cases} 
a=-1 & n < -1\\
a = n & -1 \leq n\leq +1 \\
a=+1 & n > +1
\end{cases}
\]
Para el ejemplo de clasificación, se propone usar los siguientes valores:\\
\[
W =
\begin{bmatrix}
2. &  0& 0\\
0 &  1.2& 0\\
0 &  0& 0.2
\end{bmatrix};
b = 
\begin{bmatrix}
0.9 \\
0 \\
-0.9
\end{bmatrix}
\]

A continuación,se sustituyen estos valores en el modelo:
\[
\begin{bmatrix}
a_1(t+1)\\
a_2(t+1)\\
a_3(t+1)
\end{bmatrix}
 = satlins( 
\begin{bmatrix}
2. &  0& 0\\
0 &  1.2& 0\\
0 &  0& 0.2
\end{bmatrix}
\begin{bmatrix}
a_1(t)\\
a_2(t)\\
a_3(t)
\end{bmatrix}
+
\begin{bmatrix}
0.9\\
0\\
-0.9
\end{bmatrix}
)
\]

Nota: Esta RNA realiza iteraciones hasta converger a uno de los vectores prototipo\\
Ejemplo: Diga a que calse pertenece el siguiente vector de entrada: $p^T = [-1 -1 -1]$
Solución: Se realiza la primera iteración\\
t = 0\\
\[
\begin{bmatrix}
a_1(1)\\
a_2(1)\\
a_3(1)
\end{bmatrix}
= satlins( 
\begin{bmatrix}
2. &  0& 0\\
0 &  1.2& 0\\
0 &  0& 0.2
\end{bmatrix}
\begin{bmatrix}
-1\\
-1\\
-1
\end{bmatrix}
+
\begin{bmatrix}
0.9\\
0\\
-0.9
\end{bmatrix}
=
\begin{bmatrix}
0.7\\
-1\\
-1
\end{bmatrix}
)
\]

t = 1\\
\[
\begin{bmatrix}
a_1(2)\\
a_2(2)\\
a_3(2)
\end{bmatrix}
= satlins( 
\begin{bmatrix}
2. &  0& 0\\
0 &  1.2& 0\\
0 &  0& 0.2
\end{bmatrix}
\begin{bmatrix}
0.7\\
-1\\
-1
\end{bmatrix}
+
\begin{bmatrix}
0.9\\
0\\
-0.9
\end{bmatrix}
=
\begin{bmatrix}
+1\\
-1\\
-1
\end{bmatrix}
)
\]
\textbf{Converge al patrón prototipo de la naranja}

\part{Capítulo 4}
\section{Regla de Aprendizaje del perceptrón}
Una regla de aprendizaje es un procedimiento que de manera automática modifica los valores de los pesos y bias de una RNA. A este procedimiento también se conoce como algoritmo de entrenamiento.\\
Tomamos el caso de un aprendizaje supervisado por lo que se cuenta con un conjunto de entrenamiento qe indica cuál debe ser el comportamiento correcto de la RNA:
$$ \{P_1,T_1\}, \{P_2,T_2\}, \dots, \{P_q,T_q\} $$
\newpage
\section{Arquitectura del perceptrón}
La forma general de un perceptrón es:\\
\begin{figure}[h!]
	\caption{Arquitectura del perceptrón}
	\centering
	\includegraphics[scale=.5]{perceptron}
\end{figure}\\
\textbf{Nota: el función de trasnferencia tambien puede ser HARDLIM()}\\
Será útil paa el desarrollo de la regla de aprendizaje del perceptrón tener una referencia individual a cada uno de los elementos de la RNA. Primero, consideremos la matriz de pesos:\\
\[W=
	\begin{bmatrix}
	w_{1,1} & w_{1,2}& \dots & w_{1,R}\\
	w_{2,1} & w_{2,2}& \dots & w_{2,R}\\
	\vdots  & \vdots & \vdots & \vdots\\
	w_{S,1} & w_{S,2}& \dots & w_{S,R}
	\end{bmatrix}
\]\\
Las filas son las neuronas y las columnas las entradas, por lo tanto los elementos son los pesos entre ellas.\\
Se puede definir los elementos de un vector compuesto de los elementos de la i-ésima fila de W:
\[_iW=
\begin{bmatrix}
w_{i,1}\\
w_{i,2}\\
\vdots\\
w_{i,R}
\end{bmatrix}
\]\\
Ahora se pueden representar la matriz de pesos de la siguiente manera:
\[W=
\begin{bmatrix}
	_1W^T\\
	_2W^T\\
	\vdots\\
	_SW^T
	\end{bmatrix}
\]\\
Esto nos permite escribir el i-ésimo elemento del  vector de salida, como:\\
$$ a_i = hardlim(_iW^Tp + b_i) $$
Recuerde que cada neurona de la RNA divide el espacio de entrada en dos regiones. Es valioso investigar las fornteras entre estas regiones. Comenzaremos con el sencillo caso de una sola neurona de dos entradas.\\
\begin{figure}[h!]
	\caption{Arquitectura del perceptrón para este ejemplo}
	\centering
	\includegraphics[scale=.2]{perceptronModelExample}
\end{figure}\\
El modelo matemático es:
$$a = hardlim(n)$$
$$a = hardlim(Wp + b)$$
$$a = hardlim(_1W^Tp + b)$$
$$a = hardlim(W_{1,1}P1 + W_{1,2}P2 + b)$$
\section{Análisis de frontera de desición}
Ésta frontera se determina por os vectores de entrada para los cuáles la señal n es igual a 0:
$$ n = W_{1,1}P_1 + W_{1,2}P_2 + b = 0 $$
\subsection{Ejemplo}
$$ W_{1,1} = W_{1,2} = 1, b=-1$$
Sustituyendo en la fórmula:
$$ n = P_1 + P_2 -1 = 0 $$
La ecuación anterior define una linea en el espacio. En un lado de la linea de salida de la RNA será cero y en otro lado será 1. Para dibujar la línea, se obtiene los puntos donde esta intersecta los ejes $P_1$ y $P_2$ 
\begin{enumerate}
	\item Para encontrar el putno donde intersecta con $P_2$, se toma $P_1 = 0$:\\
	$$ P_2 = -\frac{b}{W_{1,2}} = -\frac{-1}{+1} = 1, \text{con } P_1=0$$
	\newpage
	\item Para encontrar el punto donde se intersecta con $P_1$ se toma $P_2 = 0$
	$$ P_1 = -\frac{b}{W_{1,1}}=-\frac{-1}{1}=1 \text{ con } P_2 = 0$$
	Con estos puntos podemos dibujar la frontera de desición
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=.2]{graphExample}
	\end{figure}\\
\end{enumerate}
Para encontrar de que lado de la frontera corresponde a la salida 1, solo es necesario aplicar una entrada a la RNA, por ejemplo, $p=[2 \ 0]^T$:
\[W=
	[1\ 1]
	\begin{bmatrix}
	2\\
	0
	\end{bmatrix} -1 = 1
\]\\
\textbf{Nota: El vector de pesos es perpendicular a la frontera de desición y apunta a la clase +1}
\part{Capítulo 4}
Ejercicio: Dado el siguiente problema de clasificación con cuatro clases, diseñe un perceptron que resuelve este problema.
\[Clase 1 = \{ P1 =
\begin{bmatrix}
1\\
1
\end{bmatrix};
P2 = 
\begin{bmatrix}
1\\
2
\end{bmatrix}
\}
\]\\

\[Clase 2 = \{ P3 =
\begin{bmatrix}
2\\
-1
\end{bmatrix};
P4 = 
\begin{bmatrix}
2\\
0
\end{bmatrix}
\}
\]\\

\[Clase 3 = \{ P5 =
\begin{bmatrix}
-1\\
2
\end{bmatrix};
P6 = 
\begin{bmatrix}
-2\\
1
\end{bmatrix}
\}
\]\\

\[Clase 4= \{ P1 =
\begin{bmatrix}
-1\\
-1
\end{bmatrix};
P2 = 
\begin{bmatrix}
-2\\
-2
\end{bmatrix}
\}
\]\\
Solución:
Recordando, un perceptron con S neuronas, puede clasificar los datos en $2^S$. En este caso se usa S=2\\
\begin{figure}[h!]
	\centering
	\includegraphics[scale=.2]{cap4ExampleArchi}
\end{figure}\\

\begin{figure}[h!]
	\centering
	\includegraphics[scale=.2]{cap4Ex1R1}
\end{figure}

Una vez que se dibujan las fronteras de desición, se elije de que cada frontera de desición tendrá la clase +1. Así, ya es posible definir el valor de los valores deseadas para cada clase:\\
\[Clase 1 = \{ t1 =
\begin{bmatrix}
0\\
0
\end{bmatrix};
t2 = 
\begin{bmatrix}
0\\
0
\end{bmatrix}
\}
\]\\

\[Clase 2 = \{ t3 =
\begin{bmatrix}
0\\
1
\end{bmatrix};
t4 = 
\begin{bmatrix}
0\\
1
\end{bmatrix}
\}
\]\\

\[Clase 3 = \{ t5 =
\begin{bmatrix}
1\\
0
\end{bmatrix};
t6 = 
\begin{bmatrix}
1\\
0
\end{bmatrix}
\}
\]\\

\[Clase 4= \{ t7 =
\begin{bmatrix}
1\\
1
\end{bmatrix};
t8 = 
\begin{bmatrix}
1\\
1
\end{bmatrix}
\}
\]\\

Ahora se proponene los vectores de pesos que cumplan las propiedades antes mecionadas, por ejemplo:\\
\[_1W= 
\begin{bmatrix}
-3\\
-11
\end{bmatrix}
\]
 y 
 \[_1W= 
\begin{bmatrix}
1\\
-2
\end{bmatrix}
\]\\

Finalmente, se obtiene el valor de los bías:
\[_1b= -_1W^Tp=[-3 -1] 
\begin{bmatrix}
0\\
1
\end{bmatrix}=1
\]\\

\[_2b= -_2W^Tp=[1 -2] 
\begin{bmatrix}
0\\
0
\end{bmatrix}=0
\]
\begin{figure}[h!]
	\centering
	\includegraphics[scale=.2]{cap4Ex1R2}
\end{figure}

\section{Red Adaline}
Para este caso de esta RNA, el $\Delta W_i$ se calcula con:
$$ \Delta w_i = \alpha \frac{\delta e}{\delta w_i} $$
Para obtener de manera explícita esta ecuación, se parte de las siguientes expresiones:
$$ e = (t - a)^2 $$
$$ a=f(Wp + b) $$
donde f es $purelin()$\\
Para resolver la ecuación se usa la regla de la cadena:
$$ \frac{\delta e}{\delta w_i} = \frac{\delta e}{\delta a} \cdot  \frac{\delta a}{\delta f} \cdot \frac{\delta f}{\delta w_i}$$ 
Ahora se calcula por separada cada una de las siguientes derivadas paciales resultantes:
\subsection{Pesos sinápticos}
$$ \frac{\delta e}{\delta a} = -2(t-a)$$
$$ \frac{\delta a}{\delta f} = 1$$
$$ \frac{\delta f}{\delta w_i} = p$$ 
\subsection{Bias}
$$ \frac{\delta e}{\delta a} = -2(t-a)$$
$$ \frac{\delta a}{\delta f} = 1$$
$$ \frac{\delta f}{\delta w_i} = 1$$
\subsection{Regla las reglas de aprendizaje}
$$ W_i(k+1) = W_i(k) + 2\alpha(t-a)*p $$
$$ b_i(k+1) = b_i(k) + 2\alpha(t-a) $$
\textbf{Nota: Dado que adaline usa purelin como función de transferencia puede ser usada para modo regresor y modo clasificador} 
\subsection{Proceso de aprendizaje}
\begin{enumerate}
	\item Dado un conjunto de entrenamiento (es un subconjunto del data set, para la práctica se usa al 100\%).\\
	Se define la arquitectura y el modelo matemático de la RNA a usar.
	\textbf{Notas:}
	\begin{enumerate}
		\item Ya que se cuenta con el dataset, ya conocemos el número de entrada y salidas de la RNA
		\item Para estos ejemplos sencillos, podemos también determinar el número de neuronas(hasta ahora solo hemos visto, RNA de una sola capa)
		\begin{enumerate}
			\item Para el modo clasificador, como ya se sabe el número de clases, simplemente se cumple con la expresión $2^S$.\textsl{}
		\end{enumerate}
	\end{enumerate}
	\item Se pide al usuario, los siguientes valores:
	\begin{enumerate}
		\item epochmax: Se refiere al número máximo de epocas a realizar
		\item $e_{epoch}$: Es un valor pequeño al cuál se desea que llegue la señal del error
		\item El valor del factor de aprendizaje 
	\end{enumerate}
	\item Se inicializan aleatoriamente entre -1 y +1 los valores de W y b
	\item Se inicia una época de aprendizaje en la cual se propaga hacia adelante cada uno de los datos del conjunto de entrenamiento, se calcula su valor del error y se aplican las reglas de aprendizaje.
	\item Una vez terminada la época del paso 4, se calcula el error de época con la siguiente expresión:
	$$ E_{epoch} = \frac{1}{N}\sum_{j=1}^{N}e_j$$
	donde:
	\begin{itemize}
		\item N: Es el número de datos del conjunto de entrenamiento
		\item $e_j$: Es el valor del error para cada dato por separado
	\end{itemize}
	\item Se verifica si se cumple con alguno de los siguientes criterios de finalización, si no, se regresa al paso 4
	\begin{enumerate}
		\item $E_{epoch}$ = 0. Todos los datos están bien clasificados.
		\item Cuando $E_{epoch} < e_{epoch}$ 
		\item Cuando se llegue al valor epochmax
	\end{enumerate}
\end{enumerate}
\section{Capítulo 11 BackPropagation}
\textbf{Solo funciona con funciones de transferencia continuas y diferenciables en las capas ocultas}
Esta es una RNA con múltiples capas y múltiples neuronas y es completamente conectada.
La forma de representar su arquitectura es con dos vectores:
\begin{itemize}
	\item vector 1 : $ [R\ S^1\ S^2\ S^3\ \dots\ S^m] $
	\item vector 2 : $ [2 \ 3\ \dots\ 3\ 1] $
\end{itemize}
donde :
\begin{enumerate}
	\item purelin()
	\item logsig()
	\item tansig()
\end{enumerate}
\textbf{Notas: Para propagación hacia atrás}
\begin{enumerate}
	\item Las funciones de transferencia deben ser continuas, diferenciables y no lineales
	\item La función purelin() solo se usa en la capa de salida para usar al MLP en modo regresor
\end{enumerate}
\subsection{Ejemplo}
Considere el siguiente dataset y diseñe una RNA que haga la correcta clasificación.
\[p_1= 
\begin{bmatrix}
0\\
0
\end{bmatrix}, t_1=0
\]

\[p_2= 
\begin{bmatrix}
0\\
1
\end{bmatrix}, t_2=1
\]

\[p_3= 
\begin{bmatrix}
1\\
0
\end{bmatrix}, t_3=1
\]

\[p_4= 
\begin{bmatrix}
1\\
1
\end{bmatrix}, t_4=0
\]

No se puede por que no es linealmente separable\\
Inicialmente un algoritmo para entrenar un MLP fue propuesto por Papul Werbos en 1974. El aŕea continuó en desarrollo hasta llegar al back propagation. A continuación, se resuelve el problema xor usadno un método gráfico y un MLP
\section{Back-propagation}
\subsection{Foward Propagation}
$$ a^0 = P $$
$$ a^{m+1} = f^{m+1}(W^{m+1} a^{m} + b^{m+1}) $$ para m =0,1,$\dots$,(M-1)
$$ a = a^M $$ donde M es el número de capas
\subsection{BackPropagation (aprendizaje)}
EN resumen, se usan las siguientes ecuaciones:
\begin{itemize}
	\item Sensitividades
	$$ S^M = -2\dot{F}^M (n^M)(t-a) $$
	$$ S^m = \dot{F}^m (n^m)(W^{m + 1})^T\cdot S^{m + 1} $$
	para m = (M-1), ..., 2, 1\\
	\textbf{Not: Se debe obtener una ecuación de sensitividad por cada capa del MLP}\\
	donde:
	\[\dot{F}^m(n^m)= 
	\begin{bmatrix}
	\dot{f}^m(n_{1}^m) & 0 & \dots & 0\\
	\vdots & \dot{f}^m(n_{2}^m) &\ddots & \vdots\\
	0 & 0 & \dots &\dot{f}^m(n_{s^m}^m)
	\end{bmatrix}
	\]
	\textbf{Notas:}
	\begin{enumerate}
		\item Se obtiene una matriz $\dot{F}(\cdot) $
		\item Solo hay valores en la diagonal principal
		\item Es una matriz cuadrada cuya dimensión está dada por el número de neuronas en esa capa
	\end{enumerate}
	$$ \dot{f}^m(n_{j}^m) = \frac{\partial f^m (n_j^m)}{\partial n^m_j} $$ 
	\textbf{Nota: Indica que se debe obtener la derivada de la función de transferencia correspondiente}\\
	Finalmente, las reglas de aprendizaje son:
	$$ W^m(k + 1) = W^m(k) - \alpha S^m(a^{m-1})^T $$
	$$ b^m(k + 1) = b^m(k) - \alpha S^m $$
\end{itemize}
\subsection{Pasos a seguir para realizar el programa MLP}
\begin{enumerate}
	\item Se solicita al usuario los siguientes datos
	\begin{enumerate}
		\item El archivo con los datos de entrada(vector p): input\_1.txt
		\item El archivo con los valores deseados(t): target\_1.txt
		\item Se va a realizar sólo ejemplos de modo regresor. Así que el usuario debe indicar el rando de la señal. ejemplo[-2, 2]
		\item La arquitectura de la MLP que desea usar, en dos vectores:
		\[v_1: 
		\begin{bmatrix}
		1 & S^1 & S^2 & S^3 & 1
		\end{bmatrix}
		\]
		\textbf{Nota: Máximo 3 capas ocultas}
		\[v_2: 
		\begin{bmatrix}
		2 & 3 & 2 & 1
		\end{bmatrix}
		\]
		\textbf{Nota: funciones de transferencia no lineales}\\
		\textbf{Recordando}:
		\begin{enumerate}
			\item purelin()
			\item logsig()
			\item tansing()
		\end{enumerate}
	\item Valor del factor de aprendizaje ($\alpha$)
	\[v_1: 
	\begin{bmatrix}
	0.00001 & 0.0001 & 0.001 & 0.1 & .12 & \dots & 1
	\end{bmatrix}
	\]
	\item Valores de las condiciones de finalización del aprendizaje :
	\begin{itemize}
		\item Número de epocas: epochmax \textbf{No asegura el aprendizaje}
		\item Que el valor del error de entrenamiento en una época, sea menor al valor:\\ error\_epoch\_train > $\frac{1}{N}\sum_{j=1}^{N}| e_j|$ \textbf{Si asegura el aprendizaje}\\
		donde N: Es el número de datos en el conjunto de entrenamiento
		\item El usuario va a dar los siguientes valores:
		\begin{enumerate}
			\item epochval: Este valor indica cada cuantas iteraciones se llevará a cabo una época de validación
			\item numval: El número máximo de incrementos consecutivos del error\_epoch\_validation.\textbf{No asegura el aprendizaje}\\
			error\_epoch\_validation > $\frac{1}{N}\sum_{j=1}^{N}| e_j|$\\
			\textbf{Nota: aquí se usa el conjutno de validación}
		\end{enumerate}
		\item Si se sobrepasa el valor numval se finaliza el aprendizaje del MLP\\
		\textbf{Early Stopping: Evitar sobre entrenamiento}
	\end{itemize}
	\item En este momento se lleva acabo la división del dataset en tres conjutnos: entrenamiento, validación y prueba. los primeros dos se usan durante el aprendizaje y el último para validar la calidad de generalización de conocimiento que obtuvo el MLP.\\
	El usuario podra usar una de las siguientes configuraciones:
	\begin{enumerate}
		\item 80\%-10\%-10\%
		\item 70\%-15\%-15\%
	\end{enumerate}
	\end{enumerate}
	\item Se inicializan con valores aleatorios, entre -1 y +1, los parámetros del MLP
	\item Se inicia la fase del aprendizaje
	\begin{enumerate}
		\item Dado un valor de época(epoch), se verifica si es igual ó múltiplo de epochval, si es así se hace una época de validaciónn y si no se hace una época de entrenamiento
		\item Época de entrenamiento consiste en propagar hacia adelante cada uno de los datos del conjunto de entrenamiento, aplicar las reglas de aprendizaje y al final obtener el valor de error de epoca
		\item Época de validación, se usa el algoritmo Early stopping.
		\item Se repiten los pasos desde este enumerate, hasta que se cumpla uno de los criterios de finalización
	\end{enumerate}
	\item Una vez terminada la fase de aprendizaje, se realiza la validación del resultado.\\
	La validación consiste en tomar todos los valores finales de los pesos y bias del MLP y realizar la propagación hacia adelante de todos los datos del conjutno de prueba(no hay aprendizaje) y calcular el error. Este error se el llamará error de prueba.
	Para evaluar objetivamente el aprendizaje del MLP este rror debe ser realmente pequeño, de $1x10^{-3}$ ó menor y el MLP debe presentar valores muy crecanos a los valores deseados(target) en todo el rango de la señal.
	\textbf{Early Stopping}\\
	En el MLP en muchas ocasiones se puede presentar un fenómeno llamado sobreentrenamiento, que consiste en un sobreajuste del MLP a la señal.\\
	Es uno de los métodos para determinar sobrentrenamiento de la MLP. El early stopping se aplica durante una época de validación(epochval).
	En este momento, se toman los valores de pesos y bías obtenidos en la epoca anterior de entrenamiento y se fijan estos valores en la rquitectura de MLP, luego se propaga hacia adelante todos los datos del conjunto de validación y se calcula el error promedio, que se llamará error de validación. Terminando este cálculo, se regresa a las epocas de aprendizaje hasta que se vuelva a presentar un valor de época que se múltiplo de epochval y se repite el procedimiento anteriormente descrito. Finalmente selleva un contador que registre el incremento consecutivo del error de valiación y cuando se igual a numval se detiene el aprendizaje
	\textbf{algoritmo}\\
\end{enumerate}
\subsubsection{Funcionalidad}
\begin{enumerate}
	\item Cada vez que el programa finalice su ejecución se deben guardar los W's y los b's del MLP en un archivo *.txt
	\item El programa debe permitir al usuario cargar dese un archivo valores inciales de W's y b's
	\item guardar en uno o más archivos la configuración completa que usó el usuario para uqe solamente indique cuantas epocas adicionales desea realizar
\end{enumerate}
\subsubsection{Presentación de resultados}
\begin{enumerate}
	\item En la pantalla deberá aparecer los valores finales de los errores de entrenamiento y validación y el error de prueba
	\item Las siguientes gráficas:
	\begin{enumerate}
		\item Por cada capa del MLP una gráfca de la evoluciión de los W's y b's (de 1 a 3)
		\item Una gráfica de la evoluciń de los errores de entrenamiento y validación
		\item Una gráfica que dibuje con círculos los valores del conjunto de prueba y con una cruz los valores de salida del MLP al propagar hacia adelante el conjutno de prueba con el MLP entrenado
		\item Se debe guardar en un archivo txt los valores finales de W's y b's
	\end{enumerate}
\end{enumerate}
La elección de la arquitectura de un MLP. En general, no podemos decir cuantas neuronas son necesarias para obtener un adecuado comportamiento del MLP para un problema dado. Sin embargo es bueno graficar la señal a aproximar para visualizar su complejidad.
Para un primer ejemplo se desea usar un MLP para aproximar las siguientes funciones:
 $$ g(p) = 1 + sin(\frac{i \pi}{4} * p) $$
 para $-2 \le p \le 2$, tomando a i = 1, 2, 4, 8
 ¿Cómo obtengo un dataset a partir de esta información?
 \begin{enumerate}
 	\item Se genera un vector p con una frecuencia de muestreo a elegir. p=-2:0,04:2; 100 muestras
 	\item Para un valor i dado, se plica el vector p como entrada y se obtiene g(p) que serán los valores deseados
 	\item  Se deben guardar en un archvo txt los valores finales W's y b's.
 \end{enumerate}
 Sabemos que a medida que el valor de i aumenta se tendrá mayor número de periodos de la señal en el rángo dado.\\
 
 Si tomamos una MLP de tamaño fijo, analizemos su comportamiento. Por ejemplo:
 $$ V_1: [1 3 1], V_2: [2 1] $$
\end{document}
